{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Pre-Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 42000\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"Data/train.csv\")\n",
    "valid_df = pd.read_csv(\"Data/test.csv\")\n",
    "\n",
    "X_train = train_df.drop(['label'], axis=1).values.astype('float32')\n",
    "y_train = train_df['label'].values\n",
    "X_valid = valid_df.values.astype('float32')\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "img_h = 28\n",
    "img_w = 28\n",
    "n_samples = len(X_train_scaled)\n",
    "n_targets = 10\n",
    "\n",
    "print('Training samples:', n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAA9CAYAAACwXeIEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAE81JREFUeJztnXtQVOX/xz+HuCrCZoCYJYgma3ihBsQU/aKF6EgmppOO\nd1OUQssmE6dQy1LTvIxGQDkamhapGd5QIy+Yo6iM2ihqJgqKoouCAnJT3r8//O0ZjuzlnN0Dsfp5\nzTyj7J7znNc5Z/e9zz7nOc8KAIhhGIaxXez+awGGYRjGOjjIGYZhbBwOcoZhGBuHg5xhGMbG4SBn\nGIaxcTjIGYZhbBwOcoZhGBuHg5xhGMbGsW+k7fwXdx0JBh5rKh5ETceFPaSwhxT2kNJUPCRwi5xh\nGMbG4SBnGIaxcTjIGYZhbJzG6iNXnddff5327dtHKSkpNHbsWFXrvnPnDpWVlVFCQgIREWVlZRER\n0XvvvUdubm4UERFBgmC220pVHj58SDNnzqRnnnmGiIgWLVok/v9pAQAVFhbSd999R9evX6c1a9ZI\nnp8wYQLNmzePXnjhBbKza5w2iv68/PXXX0REdPz4cerTpw8lJCRQ586dG8WBaRrU1NRQVlYW7dix\ng4iIysvL6dtvvyUioh49ehAR0YgRI2jMmDHk4uJCLi4u6m0cQGMUVQkLC4ODgwMEQcC6deuMLabY\n4969e0hNTYWDgwPo0UUNSenYsSOcnZ0xdepUXL58Wa6uKsfk/v37EpeKigqlVRhzMYifnx8iIyNR\nVVUl22/btm2qe+ipqKhAUlKSwfPyeFm6dCkePnzYIB51qa6uxsiRI0FEiIyMRGRkJEaPHg1HR0c0\nb94c6enpcqtq8PfM0+iRk5ODmJgYxMTEYOLEiYiMjBRfI927d8eiRYtw+vRpVTyuX7+OKVOmQBAE\nWWX+/PlKdsVsxtpckM+fPx9OTk4QBAEjRoxAeXm5sUUVeRQXF0tOtLni7e2NrKwslJSUmFO2ySC/\nevUqnJ2dcefOHVkVX7t2DcHBwap7AEBZWRm6du0q+9wQEVatWqW6x+PExcWBiBATEyN5vG/fviAi\nuLq64sqVKw3uoSIWedy6dQvx8fHifhMRHBwc4ODggCFDhiAuLg5r167F2rVrUVxcjJqamgbx0HPv\n3j3ExsbCzc1NEp5EVC9QXVxcMG7cOKs94uLi0LZtWzRv3hyCICA4OBghISEYOHAgRo0aBX9/f/j7\n+4vb7dy5M6ZOnSp3l56sIN+6dSucnZ0hCAK6deuGe/fumVpckUd6erqioNCXxMREc9oNEuQJCQlK\nqzDmYpQWLVpg0qRJsiq+du0aiAgHDhxQ3ePKlSuKz4u/vz++//57PHjwQDWPumzZsgVOTk7o2rUr\nqqurJc+NGjUKLVu2BBHhm2++kVOdbI8tW7ZgypQp2L17N06cOIETJ07g1q1byMnJEf+uW5YtW4Y+\nffpgypQpyMvLU82joKAAycnJCA8PF4+5k5MTfH194evri7Zt26Jt27YGz01gYCCWL19uKtAtPi9X\nrlyBj4+PGJiDBg3CoEGDEBUVhSFDhiAqKkpSfH194ezsjOnTpxv69qnIIy8vDzExMUhLS6v3utPp\ndNDpdJg9e7bo5uPjI3e3npwgz8/PR2BgIARBgIeHh5yv8bI9MjMzERYWZvBFt3LlSmzevBmbN29G\njx496j3v6uqKX3/9VamH1UEeERGhtApjLkYZN24cAgMDZXWv6IN83759qnoUFhaic+fOkn13dHTE\nmDFjxNDQvxkNnb/z58+r4lGXiooK0enw4cMGl8nNzYW3tzcCAgLkHD/ZHl999RUEQYCdnZ34r6+v\nL1xdXcW/6z6n/9fLy0vVIA8MDBSP8eDBg7F48WLJsT5y5AiOHDkCJycnJCcn4+TJkzh58iSSkpLw\nv//9D0SEuLg4qz3qUllZiddee01seY8cORIPHz402c1WWlqK5ORkREREoLi4WBUPQ1y9ehVXr14V\nM+ypDPKsrCx07dpVPAA///yznNVkewwdOlTy5g8ODkZsbCxiY2Px999/i8uVlZUhPz8fISEhkuWH\nDRum1MMmgnzevHkgIty6dctsxTqdDhqNRvUg/+STT+p1aRn6EN+zZw86dOhgsGW+fv16qz3qsmjR\nIhARJk6caLTFf/v2bXh7e4OIkJuba65K2R7z589HcnIycnJykJycbLKMGTNGDLUZM2bI2TXZHuvX\nr8eKFStw8eJFg8+np6cjPT3d4LEvLS2Fj48PunTpUu/bjFKPuuj7qIkIY8aMwe3bt+WsZgrVsiwt\nLQ1paWmSbp2nJsjXrVuHdevWiS9GjUaD4cOHy+23leVRW1uLqKgo8Y2/ceNGZGRkmKx47ty5sLOz\nE9cJCAjA9u3blXjYRJBv27ZNdpADQGhoqKpBXl1dDa1WK9nvXr16Ga00MTHR4Nd5f39/5OfnW+xR\nl/LycgQEBICI8O+//xpdLjc3V9y+mkEeFBSE5ORkc/UBAAYMGABBEBAQEACdTidnFdUbYXXJzs7G\nxx9/DHd3dxAR/vzzT1U9PDw8QESYMGGCnGtXclDleFRXV2P16tVYvXo1PD09n64gLywsRJcuXdCl\nSxcxyMePH6+kClkep06dkrzpjbzh67F582bJetHR0Uo8FB+Tqqoq9O/fv1GDfM+ePYqDXM2W35Il\nSyTH2MnJydQHJoBHfbfdu3evF+YdO3Y01Cer+LzonSZPnmyy/70hg1zOMS4rK0OnTp1ARKa+kVjs\nIZfKykosWLAAfn5+ICI0b94cvXv3Nhe0ij127twpjmQzVHdxcTF0Oh2KioqU6Ft1PO7evYsZM2bA\nz88PHTp0QIcOHdCyZUsxyN3d3bFgwQJUVlZa4iEpTXIceUlJCfXv35/OnDkjPubm5kaDBw9WfVuX\nL18W/+/u7k4ODg6y1uvZsye5u7vT3bt3VXcyhKOjI40fP5727t3bKNsjenTM7e2VvUQ2bdpEy5Yt\nU2X7M2fOlPwdFBREkZGRJtd5/vnnaevWrRQVFUXHjh0TH//nn38etVyspLKykoiI/P39TY7j//zz\nz4mISKPRULNmzazeLhHRuXPn6Pz58zR58mSzy54/f54uXLhAQ4cOpaFDh6qy/ceprKyk1atX04MH\nD8THWrduTTdu3KD8/HwiItqxYwfl5+dTREQEJScnU2BgIHl4eKjqUVVVRfPnzxc93N3diYjoxo0b\nlJiYSEREiYmJVFRURM7OzhQdHU1LliwhR0dHVT0e5/79+7RixYp6jz/33HNkZ2dHOp2OPv30Uzpw\n4AB9+eWXFBwcbPnG5KS9CkUR165dqzdsyMwIFbmfYvXYv3+/2HIKDw+X8+kooh9DTETw8fFBaWmp\nXA/Fx6SmpgbTpk1r1BY5APj6+iI6OtpYX6aEhQsXwt3dXc65kuVBj7WqV69ebdZBz/Xr19GqVSvJ\n+gb6cxUfj6CgILPdKgDEi25vvvmmHF1ZHjk5OfD19ZXVtaLVaiEIguxuGCUeerZt24Z27doZvMis\nH7WSmJho7oKz1R46nU7MisGDB+OHH35Ahw4d4O7ubnT44RdffKG6x+NUVFQgJiYGvXv3lpRjx47h\n3LlzWLNmjegzfPhwpR6S0uSCXKfTSa6IExF69OihKGBN7LyEu3fv1nuzy+1aAYDt27dL1jXSd69K\nkP8XfeQAkJGRAXt7e5w7d85s5SkpKSAi7N27VxUPa4IcAHx8fCTrx8fHW+Shp7CwEBqNBu3atUNZ\nWZnJbetHOMm88UO2h34Ymzn0o1UaMsiBR9cMLl++LCnx8fHQarXQarUIDQ3FqVOnlDgo9qiurkaf\nPn0MBnZISAhCQkIwadIkTJo0CRqNBoIgoHXr1igsLFTVQyn6EUhqBDnPtcIwDGPryEl7FYps3nnn\nHfFTqlevXujVq5clrXFjn2ISbt++Xa/Vp6RFfvLkySe+RQ4Anp6esrZXVFQEFxeXJtMinzt3boO0\nyM11l5SXl4tDIdeuXStHVbWW38GDB3Hw4EGxVZqTk6NkddU8qqqqUFVVhRUrVsDb2xtRUVGyuucs\n9cjMzISjoyOICG5uboiJiTE4br7uKChj9wBY4yGXo0eP4tlnn1WtRd6kLnYWFRXRpUuXiOjRxb24\nuDgiInJycmqQ7Wk0Gho9ejT99NNPDVL/k4T+ApIpNBoNdevWjZYvX069evVS7SKfpZSWlkr+1mq1\nVtVXVVVF9+/fp4KCApPL3b17l0pKSoiIyM/Pz6ptKuX8+fNERCQIAr399tvUqVMn1bdx+vRpevHF\nF6lly5ZGl9FfSPzggw8oIiKC3njjDQoJCaFNmzZR+/btVXfq3bs3nT17lh4+fEguLi7Utm1bo8sK\ngkAeHh7Upk0b1T3ksnPnTvE1ogpy0l6FYpabN2+iX79+4vwHJibDkossD32/rr6EhIQYu2gpobi4\nWDL/R0xMDGpra+V62FSLfPLkyXjllVckw/cKCgpQUFCA9PR0zJ07F0FBQejWrZvo99lnn1ntQVa0\nyNPS0sQWmr4YaBEqOh4FBQVwdXXFq6++anLb69evF4dLGrthxhoPU4wePRqjR49WOuxQtsfNmzfh\n6emJs2fPKqr4yJEjCAgIwIsvvogLFy5Y7WEJOTk54vwrAwYMkLOKah41NTWoqalBaWkpFi5cKOnT\n12q1uHr1qlIPSWkyQZ6UlCTuWFhYmKyDYwZZHiUlJfUurgYHB5u6WQG3bt3C2LFjxeVdXFxMTY5k\n80GemZkJIsKcOXOwbNkyhIeHw8XFBS4uLrC3t0ffvn2xfft2HDlyBLNmzQIRYdeuXVZ7PB7kHTt2\nxKVLl8z65ubmIjo6WrLuqlWrDH3QKjoe+rHhpoI8IyMDbm5uICLMnj3brKslHqYICgpCUFAQBEFA\ndna20tXNeqxduxYTJkywyC0vLw9arRb9+vXD/fv3rfKwhO7du4sZI/MisCoelZWViI6ORnR0dL1J\nuwICAiydOqHpBfnGjRvFoUKhoaG4fv26rANkBtkehw4dEu/W05fevXuL80NcunQJly5dQk5ODk6e\nPFlvJr7GuEV/4sSJ/1mQl5SUwN/fH15eXvDy8sL48eORmJiIxMREHD9+XLLshQsXVAvyxz9gicjk\nzTB5eXn46KOPxDv89GXSpEnG5tuwKMi1Wm296zbZ2dnIzs5GixYtxNfPjRs3TFVnsYcxTpw4IRm5\n0VBBLvOmL4OkpqaCiPDHH39Y5aGUpUuXitcNJk+eLLe/XrZHbm4uZs2ahT179ohz61y7dg0ZGRkI\nDw83OJWtp6enNbNjNq0gLykpgZ+fn7hzW7dulbNjclDkkZqaCldXV4NjYvUBZuz51NRUpR6KX5h1\n7+ps7CBXgv4CshpBXlxcXC/M7e3t0bVrVyQkJEhK9+7dodFo6p2bLl264ObNm1Z56NEPcyMipKWl\niY8XFRVh7ty54sXV0NBQuV0qFnkY48SJE5JJsxoiyHfv3o3g4GCLb4GvqqqCVqs1N4Wraq/Tuhd/\n6f8vhMpoASvyKCgogLe3t6RHYcCAAfD19TUY4EOHDoW/vz+WL19ujUfTCvKUlBTJTqakpMjdOXMo\nfjHoP7XlFo1Gg9TUVHNjijnIrfDYsmWLonOiIMQVeejR/7iFr68vdu7ciQ8//FDyDaBNmzbYvHmz\nuWqs9jBEY7TIy8vL4e3tjdTUVLk/3lGPsLAwBAYGWuVhjvLycnz99dfw8PCAh4cHBEGAo6MjkpKS\nlFQjy+PixYviDVhyyqlTp5T2OjT9IN+4cSPs7e0hCAIcHBzMXSRTguIXw7179zBw4EBZIeHq6oo9\ne/ZY6vHEBnl1dTUCAwPNzZcu26O2tla8eCi3aLVabNiwwdI5LEySl5cndp/ULfqW8KZNm8xVoYqH\nIeq2yDt16mTqR1es8li3bh2cnJwwZ84cxUODFy9eDI1GY641qvh4HD16FL/99hsAIDk5GZ07d64X\noCamzbXKo7q6Gr/88ku9Fnjz5s0xZcoUyXTLK1eulPPDGnI8mlaQA4/Gdr700kv48ccfle6gKSx6\nc1RUVGD79u2S2+HrlmnTpqGoqEjJV0tVgvzAgQMSj4MHDyqtwpiL6oSHh5ub4EyRR21tLW7fvo34\n+HijvxQ0btw4xMfHY8OGDUreKBYdj8LCQuzfvx8TJkxASEgIoqKikJmZiczMTLnbVcXjcer+1NiW\nLVsa1CMlJUX8YY1du3aZHel19uxZxMbGws7ODrNmzVL9Yufvv/8OV1dXeHp6in3hgiCIv8yzePFi\nc1VY5ZGRkYHs7Gy89dZbeP/995GWlibOb15aWioWCzGbsQIAagQaZSOPYejXkZuKB1HTcVHVo7q6\nmoKDgyk2NtbU5E5N+dzYrEerVq2oqKiIiB79KHRDe5w6dYpWrFhBWVlZVFJSQgMHDqRhw4ZRs2bN\nxEmzDh8+THv37qWCggJq3749TZ8+nWJiYlT10Lv07NmTKisrCQAFBgZSVFQUvfvuu0RElo4Zb8qv\nD+kCHOQNzlMV5DJhDylWe+h0OvLy8iJBeFRVbW1to3mUl5fT4sWL6dChQ3TmzBlq1qwZ5eXlEdGj\nG3VCQ0OpZ8+e1L9/f7kzDj4x50UlOMgfo6l4EDUdF/aQYpMeRUVF5OXlRS+//DIRkWQK6Mb0UAn2\nkMJB/hhNxYOo6biwhxT2kMIeUpqKh3SBRgpyhmEYpoHgaWwZhmFsHA5yhmEYG4eDnGEYxsbhIGcY\nhrFxOMgZhmFsHA5yhmEYG4eDnGEYxsbhIGcYhrFxOMgZhmFsHA5yhmEYG4eDnGEYxsbhIGcYhrFx\nOMgZhmFsHA5yhmEYG4eDnGEYxsbhIGcYhrFxOMgZhmFsHA5yhmEYG4eDnGEYxsbhIGcYhrFxOMgZ\nhmFsHA5yhmEYG+f/AIU7wdbB/5uBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d44c40f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The data that we are interested in is made of 28x28 images of digits, let's\n",
    "# have a look at the first images, stored in X_train. For these\n",
    "# images, we know which digit they represent: it is given by the correspondent y_train.\n",
    "images_and_labels = list(zip(X_train, y_train))\n",
    "for index, (image, label) in enumerate(images_and_labels[:10]):\n",
    "    plt.subplot(2, 10, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.reshape(img_h, img_w), cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model_name, y_test, predicted, df_cm):\n",
    "    \"\"\"\n",
    "    Generates a good visualization for confusion matrices.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : string\n",
    "        The model used to train the data.\n",
    "    y : array-like, shape (n_samples, n_targets)\n",
    "        The test data targets.\n",
    "    predicted : array-like, shape (n_samples, n_targets)\n",
    "        The predicted targets.\n",
    "    df_cm : pandas dataframe, shape (n_targets, n_targets)   \n",
    "        The confusion matrix.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(5.5,4))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.title(model_name+' \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test,predicted)))\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X, y, fitted_model):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "    fitted_model : sklean fitting model\n",
    "        Instance for the model used to fit X.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(9.8,5), dpi=100)\n",
    "    \n",
    "    for i, plot_type in enumerate(['Decision Boundary', 'Decision Probabilities']):\n",
    "        plt.subplot(1,2,i+1)\n",
    "\n",
    "        mesh_step_size = 0.01  # step size in the mesh\n",
    "        x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "        y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, mesh_step_size), np.arange(y_min, y_max, mesh_step_size))\n",
    "        if i == 0:\n",
    "            Z = fitted_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            try:\n",
    "                Z = fitted_model.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
    "            except:\n",
    "                plt.text(0.4, 0.5, 'Probabilities Unavailable', horizontalalignment='center',\n",
    "                     verticalalignment='center', transform = plt.gca().transAxes, fontsize=12)\n",
    "                plt.axis('off')\n",
    "                break\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        plt.scatter(X[y.values==0,0], X[y.values==0,1], alpha=0.4, label='Edible', s=5)\n",
    "        plt.scatter(X[y.values==1,0], X[y.values==1,1], alpha=0.4, label='Posionous', s=5)\n",
    "        plt.imshow(Z, interpolation='nearest', cmap='RdYlBu_r', alpha=0.15, \n",
    "                   extent=(x_min, x_max, y_min, y_max), origin='lower')\n",
    "        plt.title(plot_type + '\\n' + \n",
    "                  str(fitted_model).split('(')[0]+ ' Test Accuracy: ' + str(np.round(fitted_model.score(X, y), 5)))\n",
    "        plt.gca().set_aspect('equal');\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9, bottom=0.08, wspace=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_curve(SVC(kernel='rbf'), X_train_scaled, y_train, \"gamma\", np.logspace(-7, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', gamma=0.001).fit(X_train_scaled, y_train)\n",
    "svm_predicted = svm.predict(X_valid_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(svm, X_train_scaled, y_train, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_and_predictions = list(zip(X_valid_scaled, svm_predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[104]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.reshape(img_h, img_w), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('%i' % prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curves (SVM, Linear kernel, $C=0.001$)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "estimator = SVC(kernel='linear', C=0.001)\n",
    "plot_learning_curve(estimator, title, X_train_scaled, y_train, (0.7, 1.01), cv=cv, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear', C=0.001).fit(X_train_scaled, y_train)\n",
    "svm_predicted = svm.predict(X_valid_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_and_predictions = list(zip(X_valid_scaled, svm_predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[104]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.reshape(img_h, img_w), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('%i' % prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_scaled = X_train_scaled.reshape(n_samples, img_h, img_w, 1)\n",
    "x_valid_scaled = x_valid_scaled.reshape(n_samples, img_h, img_w, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The y_train is not split into 10 distinct class labels, but rather \n",
    "# are represented as a single array with the class values\n",
    "y_train = to_categorical(y_train, n_targets)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture\n",
    "\n",
    "---\n",
    "\n",
    "1. Basic Concepts:   \n",
    "    * [2D Convolution](https://keras.io/layers/convolutional/#convolution2d)\n",
    "    \n",
    "    The main concept to implement a CNN. This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.\n",
    "    \n",
    "    * [Max Pooling](https://keras.io/layers/pooling/#maxpooling2d)\n",
    "    \n",
    "    Reduces the size of the filter maps, by applying a max filter to non-overlapping subregions. A max pooling layer with pooling_size=2 will reduce the number total number of parameters in the filter map by a factor of 4.\n",
    "    \n",
    "    * [Dropout](https://keras.io/layers/core/#dropout)\n",
    "    \n",
    "   Consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting.\n",
    "   \n",
    "   * [Flatten](https://keras.io/layers/core/#flatten)\n",
    "   \n",
    "   Flattens the input. Does not affect the batch size.\n",
    "   \n",
    "   * [Dense](https://keras.io/layers/core/#dense)\n",
    "   \n",
    "   Just a regular densely-connected NN layer.\n",
    "   \n",
    "   * [Activation](https://keras.io/layers/core/#activation)\n",
    "   \n",
    "   Applies an activation function to an output.\n",
    "\n",
    "2. Architecture:\n",
    "\n",
    "    * Sequential Model\n",
    "    * Convolutional Layer \n",
    "    * MaxPooling\n",
    "    * Convolutional Layer \n",
    "    * MaxPooling\n",
    "    * Dropout\n",
    "    * Dense Layer\n",
    "\n",
    "3. Obs:\n",
    "\n",
    "     * [Epoch vs Batch Size vs Iterations](https://stackoverflow.com/questions/4752626/epoch-vs-iteration-when-training-neural-networks)\n",
    "     * [Optimizers](https://keras.io/optimizers/)\n",
    "     * [Loss Functions](https://keras.io/losses/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu', (None, 1, img_h, img_w), border_mode='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu', (None, 1, img_h, img_w), border_mode='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "model.fit(X_train_scaled, y_train, batch_size=32, nb_epoch=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict_classes(x_valid_scaled)\n",
    "\n",
    "np.savetxt('mnist-vggnet.csv', np.c_[range(1,len(pred)+1),pred], delimiter=',', header = 'ImageId,Label', comments = '', fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
