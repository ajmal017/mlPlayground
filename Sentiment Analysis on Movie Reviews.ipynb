{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis on Movie Reviews\n",
    "---\n",
    "\n",
    "The dataset is comprised of tab-separated files with phrases from the Rotten Tomatoes dataset. The train/test split has been preserved for the purposes of benchmarking, but the sentences have been shuffled from their original order. Each Sentence has been parsed into many phrases by the Stanford parser. Each phrase has a PhraseId. Each sentence has a SentenceId. Phrases that are repeated (such as short/common words) are only included once in the data.\n",
    "\n",
    "The sentiment labels are:\n",
    "\n",
    "* 0 - negative\n",
    "* 1 - somewhat negative\n",
    "* 2 - neutral\n",
    "* 3 - somewhat positive\n",
    "* 4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Data/sentiment-train.tsv', sep='\\t', header=0)\n",
    "df_valid = pd.read_csv('Data/sentiment-test.tsv',  sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "\n",
    "As each sentence was parsed into many phrases, let's filter the complete phrase for each sentence first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train.sort_values(['SentenceId', 'PhraseId']).groupby(['SentenceId']).first().reset_index()\n",
    "# df_valid = df_valid.sort_values(['SentenceId', 'PhraseId']).groupby(['SentenceId']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Look at the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df_train['Sentiment'].value_counts()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b6142431d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD0CAYAAACSA/HcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKANAkgr1/wA2DU4putyuhAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b616193668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative: 34345\n"
     ]
    }
   ],
   "source": [
    "print('Negative:', s[0] + s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 42133\n"
     ]
    }
   ],
   "source": [
    "print('Positive:', s[3] + s[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(df_train['Sentiment'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Pre-Processing\n",
    "\n",
    "Before training any model, let's do more data pre-processing. Specifically, I'm goint to:\n",
    "\n",
    "* Remove stop words\n",
    "* Put all phrases in lower case\n",
    "* Stem words\n",
    "\n",
    "*PS: found that most of the code below can be done at once with [Keras](https://keras.io/preprocessing/text/) Tokenizer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}', '='])\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs_train = []\n",
    "for df in [df_train, df_valid]:\n",
    "    df['Parsed'] = df['Phrase'].apply(lambda x: x.lower())\n",
    "    df['Parsed'] = df['Phrase'].apply(lambda x: word_tokenize(x))\n",
    "    df['Parsed'] = df['Phrase'].apply(lambda x: [word for word in str(x).split() if word not in stop_words])\n",
    "    df['Parsed'] = df['Parsed'].apply(lambda x: [stemmer.stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, seri, escapad, demonstr, adag, good, goos,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[a, seri, escapad, demonstr, adag, good, goos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>[a, seri]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>[a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>[seri]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment                                             Parsed  \n",
       "0          1  [a, seri, escapad, demonstr, adag, good, goos,...  \n",
       "1          2     [a, seri, escapad, demonstr, adag, good, goos]  \n",
       "2          2                                          [a, seri]  \n",
       "3          2                                                [a]  \n",
       "4          2                                             [seri]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>[an, intermitt, pleas, most, routin, effort]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>[an, intermitt, pleas, most, routin, effort]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td>[an]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>[intermitt, pleas, most, routin, effort]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>[intermitt, pleas, most, routin]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...   \n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...   \n",
       "2    156063        8545                                                 An   \n",
       "3    156064        8545  intermittently pleasing but mostly routine effort   \n",
       "4    156065        8545         intermittently pleasing but mostly routine   \n",
       "\n",
       "                                         Parsed  \n",
       "0  [an, intermitt, pleas, most, routin, effort]  \n",
       "1  [an, intermitt, pleas, most, routin, effort]  \n",
       "2                                          [an]  \n",
       "3      [intermitt, pleas, most, routin, effort]  \n",
       "4              [intermitt, pleas, most, routin]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's map each word to an ID..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paula.ceccon.ribeiro\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(df_train['Parsed'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary size: 11842\n"
     ]
    }
   ],
   "source": [
    "print ('Dictionary size:', len(dictionary)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11842"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(np.concatenate(df_train['Parsed'].values, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to skip words found in test but not in training data\n",
    "diff = set(np.concatenate(df_valid['Parsed'].values, axis=0)) - set(np.concatenate(df_train['Parsed'].values, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train, df_valid]:\n",
    "    df['Dict'] = df['Parsed'].apply(lambda x: [dictionary.token2id[word] for word in x if word not in diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Parsed</th>\n",
       "      <th>Dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, seri, escapad, demonstr, adag, good, goos,...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 5, 8, 9, 10, 11, 12, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[a, seri, escapad, demonstr, adag, good, goos]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>[a, seri]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>[a]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>[seri]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment                                             Parsed  \\\n",
       "0          1  [a, seri, escapad, demonstr, adag, good, goos,...   \n",
       "1          2     [a, seri, escapad, demonstr, adag, good, goos]   \n",
       "2          2                                          [a, seri]   \n",
       "3          2                                                [a]   \n",
       "4          2                                             [seri]   \n",
       "\n",
       "                                                Dict  \n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 5, 8, 9, 10, 11, 12, ...  \n",
       "1                              [0, 1, 2, 3, 4, 5, 6]  \n",
       "2                                             [0, 1]  \n",
       "3                                                [0]  \n",
       "4                                                [1]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Parsed</th>\n",
       "      <th>Dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>[an, intermitt, pleas, most, routin, effort]</td>\n",
       "      <td>[575, 5848, 765, 908, 1343, 971]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>[an, intermitt, pleas, most, routin, effort]</td>\n",
       "      <td>[575, 5848, 765, 908, 1343, 971]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td>[an]</td>\n",
       "      <td>[575]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>[intermitt, pleas, most, routin, effort]</td>\n",
       "      <td>[5848, 765, 908, 1343, 971]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>[intermitt, pleas, most, routin]</td>\n",
       "      <td>[5848, 765, 908, 1343]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...   \n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...   \n",
       "2    156063        8545                                                 An   \n",
       "3    156064        8545  intermittently pleasing but mostly routine effort   \n",
       "4    156065        8545         intermittently pleasing but mostly routine   \n",
       "\n",
       "                                         Parsed  \\\n",
       "0  [an, intermitt, pleas, most, routin, effort]   \n",
       "1  [an, intermitt, pleas, most, routin, effort]   \n",
       "2                                          [an]   \n",
       "3      [intermitt, pleas, most, routin, effort]   \n",
       "4              [intermitt, pleas, most, routin]   \n",
       "\n",
       "                               Dict  \n",
       "0  [575, 5848, 765, 908, 1343, 971]  \n",
       "1  [575, 5848, 765, 908, 1343, 971]  \n",
       "2                             [575]  \n",
       "3       [5848, 765, 908, 1343, 971]  \n",
       "4            [5848, 765, 908, 1343]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4217352300397283\n",
      "Most Informative Features\n",
      "                  atroci = True                0 : 2      =    186.6 : 1.0\n",
      "                    crap = True                0 : 2      =    186.6 : 1.0\n",
      "                unimagin = True                0 : 2      =    156.1 : 1.0\n",
      "                88-minut = True                0 : 2      =    133.3 : 1.0\n",
      "                  stupid = True                0 : 3      =    131.5 : 1.0\n",
      "               indescrib = True                0 : 2      =    118.0 : 1.0\n",
      "                    poor = True                0 : 3      =    117.9 : 1.0\n",
      "                   dazzl = True                4 : 2      =    113.0 : 1.0\n",
      "                  polish = True                4 : 2      =    109.6 : 1.0\n",
      "                  redund = True                0 : 2      =    107.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "features = [(word_feats(row['Parsed']), row['Sentiment']) for index, row in df_train.iterrows()]\n",
    "\n",
    "cutoff = int(len(features)*3/4)\n",
    "trainfeats = features[:cutoff]\n",
    "validfeats = features[cutoff:]\n",
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "\n",
    "print('Accuracy:', nltk.classify.util.accuracy(classifier, validfeats))\n",
    "\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  atroci = True                0 : 2      =    183.8 : 1.0\n",
      "                  insult = True                0 : 3      =    175.4 : 1.0\n",
      "                88-minut = True                0 : 2      =    131.3 : 1.0\n",
      "                  delici = True                4 : 2      =    129.7 : 1.0\n",
      "                  devoid = True                0 : 3      =    128.8 : 1.0\n",
      "                   worst = True                0 : 4      =    125.4 : 1.0\n",
      "                  polish = True                4 : 2      =    123.9 : 1.0\n",
      "                pretenti = True                0 : 3      =    116.4 : 1.0\n",
      "               indescrib = True                0 : 2      =    116.3 : 1.0\n",
      "                    wors = True                0 : 3      =    112.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(features)\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training = [word_feats(row['Parsed']) for index, row in df_valid.iterrows()]\n",
    "y_pred = [classifier.classify(t) for t in training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PhraseId': df_valid['PhraseId'], 'Sentiment': y_pred})\n",
    "submission.to_csv('sentiment-output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get ready to use an LSTM model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df_train['Dict'].apply(lambda x: len(x)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = df_train['Dict'].apply(lambda x: len(x)).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase size mean and std: 4.26, 3.85\n"
     ]
    }
   ],
   "source": [
    "print('Phrase size mean and std: {0:.2f},'.format(mean), '{0:.2f}'.format(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = np.round(mean + 2*std).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq len: 12\n"
     ]
    }
   ],
   "source": [
    "print('Seq len:', seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['Sentiment'], axis=1)\n",
    "y_train = df_train['Sentiment']\n",
    "X_valid = df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM, Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(np.array(X_train['Dict']), maxlen=seq_len)\n",
    "X_valid = sequence.pad_sequences(np.array(X_valid['Dict']), maxlen=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 12, 64)            757888    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 12, 32)            6176      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 6, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 847,141\n",
      "Trainable params: 847,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 104560 samples, validate on 51500 samples\n",
      "Epoch 1/5\n",
      "62s - loss: 0.5186 - acc: 0.8430 - val_loss: 0.5272 - val_acc: 0.8426\n",
      "Epoch 2/5\n",
      "58s - loss: 0.4839 - acc: 0.8526 - val_loss: 0.5335 - val_acc: 0.8385\n",
      "Epoch 3/5\n",
      "59s - loss: 0.4313 - acc: 0.8684 - val_loss: 0.3976 - val_acc: 0.8438\n",
      "Epoch 4/5\n",
      "59s - loss: 0.2955 - acc: 0.8708 - val_loss: 0.4017 - val_acc: 0.8386\n",
      "Epoch 5/5\n",
      "58s - loss: 0.2804 - acc: 0.8770 - val_loss: 0.4121 - val_acc: 0.8389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b6a961ba20>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vector_length = 64\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(dictionary), embedding_vector_length, input_length=seq_len))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(128, recurrent_dropout=0.2))\n",
    "model.add(Dense(num_labels))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=2, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66144/66292 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PhraseId': df_valid['PhraseId'], 'Sentiment': y_pred})\n",
    "submission.to_csv('sentiment-output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
